TASK 1 : 

Task 1 focused on summarizing dialogues from a dataset using the FLAN-T5 model.
The dataset used was called "Dialogue sum."
Initial setup involved installing Python libraries including PyTorch, Torch data, and Transformers from Hugging Face.
The FLAN-T5 model was loaded along with its tokenizer from Hugging Face Transformers library.
Attempts were made to summarize conversations using the model, but initial results were not satisfactory.
Different prompts were experimented with to improve summarization, including zero-shot inference and in-context learning.
One-shot and few-shot inference methods were explored, providing the model with correct examples to improve summarization.
The impact of configuration parameters such as sampling temperature on model responses was discussed.
Experimenting with different temperature values can lead to varied and creative responses from the model.
Overall, the lab aimed to familiarize users with prompt engineering and model fine-tuning techniques for better summarization results.
